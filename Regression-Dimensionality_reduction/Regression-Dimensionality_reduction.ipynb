{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0494adc8",
   "metadata": {},
   "source": [
    "# Project: Dimensionality reduction\n",
    "\n",
    "The project consists in reducing the dimensionality of a problem with small sample sizes. 8 data points are available, each associated to over 1650 possible predictors. The project aims at predicting a continuous target value of 8 provided samples.\n",
    "\n",
    "This notebook is structured to reflect the modelling framework:\n",
    "- Data exploration\n",
    "- Data cleaning\n",
    "- Visualisation\n",
    "- Baseline modelling\n",
    "- Model refinement\n",
    "\n",
    "The framework steps are further detailed in the notebook. This notebook should be executed in a folder containing the provided dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff217e7",
   "metadata": {},
   "source": [
    "# 0. Import packages and data\n",
    "\n",
    "## 0.1 Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0358f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_palette('viridis')\n",
    "colours = sns.color_palette('viridis', n_colors=8)\n",
    "\n",
    "# Imputing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modelling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40268975",
   "metadata": {},
   "source": [
    " ## 0.2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0c7c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['~$signment Data scientist chemistry.docx',\n",
       " 'anonymised.csv',\n",
       " 'dragon_molecular_descriptor_list.pdf',\n",
       " 'devinyak2014.pdf',\n",
       " 'dragon data of available SMILES.csv',\n",
       " 'Anonymised.ipynb',\n",
       " 'Data Scientist Chemometrics assignment.pptx',\n",
       " 'Submission.py',\n",
       " 'Submission.zip',\n",
       " 'Predictive model.ipynb',\n",
       " 'Submission.pdf',\n",
       " 'ratio_vs_power.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'Assignment Data scientist chemistry.docx',\n",
       " 'Submission.ipynb',\n",
       " 'Submission',\n",
       " 'Regression model.ipynb',\n",
       " 'Data Scientist Chemometrics assignment.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The working directory to execute this code should be a folder containing both datasets provided\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7810615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (4524, 1667)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature1657</th>\n",
       "      <th>Feature1658</th>\n",
       "      <th>Feature1659</th>\n",
       "      <th>Feature1660</th>\n",
       "      <th>Feature1661</th>\n",
       "      <th>Feature1662</th>\n",
       "      <th>Feature1663</th>\n",
       "      <th>Feature1664</th>\n",
       "      <th>Feature1665</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>154.28</td>\n",
       "      <td>5.32</td>\n",
       "      <td>15.89</td>\n",
       "      <td>28.28</td>\n",
       "      <td>17.31</td>\n",
       "      <td>24.92</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>152.16</td>\n",
       "      <td>8.01</td>\n",
       "      <td>11.93</td>\n",
       "      <td>19.52</td>\n",
       "      <td>12.41</td>\n",
       "      <td>31.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>122.18</td>\n",
       "      <td>6.43</td>\n",
       "      <td>11.50</td>\n",
       "      <td>18.75</td>\n",
       "      <td>12.26</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>102.15</td>\n",
       "      <td>6.01</td>\n",
       "      <td>9.01</td>\n",
       "      <td>17.07</td>\n",
       "      <td>9.72</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>128.14</td>\n",
       "      <td>7.54</td>\n",
       "      <td>9.93</td>\n",
       "      <td>17.52</td>\n",
       "      <td>10.41</td>\n",
       "      <td>26.83</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "Id                                                                           \n",
       "6309    154.28      5.32     15.89     28.28     17.31     24.92      0.55   \n",
       "7794    152.16      8.01     11.93     19.52     12.41     31.50      0.63   \n",
       "2767    122.18      6.43     11.50     18.75     12.26     20.67      0.61   \n",
       "3365    102.15      6.01      9.01     17.07      9.72     21.50      0.53   \n",
       "3733    128.14      7.54      9.93     17.52     10.41     26.83      0.58   \n",
       "\n",
       "      Feature7  Feature8  Feature9  ...  Feature1657  Feature1658  \\\n",
       "Id                                  ...                             \n",
       "6309      0.98      0.60      2.27  ...            0            0   \n",
       "7794      1.03      0.65      2.86  ...            0            0   \n",
       "2767      0.99      0.65      2.30  ...            0            0   \n",
       "3365      1.00      0.57      3.07  ...            0            0   \n",
       "3733      1.03      0.61      2.98  ...            0            0   \n",
       "\n",
       "      Feature1659  Feature1660  Feature1661  Feature1662  Feature1663  \\\n",
       "Id                                                                      \n",
       "6309            1            0        -3.64        -3.83        -3.87   \n",
       "7794            0            0        -2.17        -2.20        -2.15   \n",
       "2767            0            0        -3.03        -3.15        -3.15   \n",
       "3365            0            0        -2.24        -2.27        -2.23   \n",
       "3733            0            0        -0.73        -0.58        -0.46   \n",
       "\n",
       "      Feature1664  Feature1665  Target  \n",
       "Id                                      \n",
       "6309         2.68        -2.51     NaN  \n",
       "7794         1.31        -1.48     NaN  \n",
       "2767         1.51        -1.03     NaN  \n",
       "3365         1.26        -0.20     NaN  \n",
       "3733        -0.33         0.54     NaN  \n",
       "\n",
       "[5 rows x 1667 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('anonymised.csv', header=0)\n",
    "all_data.set_index('Id', inplace=True)\n",
    "\n",
    "# Cursory check of all data\n",
    "print(f'DataFrame shape: {all_data.shape}')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf69aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Ss</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Ms</th>\n",
       "      <th>...</th>\n",
       "      <th>Neoplastic-80</th>\n",
       "      <th>Neoplastic-50</th>\n",
       "      <th>Infective-80</th>\n",
       "      <th>Infective-50</th>\n",
       "      <th>BLTF96</th>\n",
       "      <th>BLTD48</th>\n",
       "      <th>BLTA96</th>\n",
       "      <th>ALOGPS_logP</th>\n",
       "      <th>ALOGPS_logS</th>\n",
       "      <th>Slope</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aroma_molecule_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>154.28</td>\n",
       "      <td>5.32</td>\n",
       "      <td>15.89</td>\n",
       "      <td>28.28</td>\n",
       "      <td>17.31</td>\n",
       "      <td>24.92</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>152.16</td>\n",
       "      <td>8.01</td>\n",
       "      <td>11.93</td>\n",
       "      <td>19.52</td>\n",
       "      <td>12.41</td>\n",
       "      <td>31.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>122.18</td>\n",
       "      <td>6.43</td>\n",
       "      <td>11.50</td>\n",
       "      <td>18.75</td>\n",
       "      <td>12.26</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>102.15</td>\n",
       "      <td>6.01</td>\n",
       "      <td>9.01</td>\n",
       "      <td>17.07</td>\n",
       "      <td>9.72</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>128.14</td>\n",
       "      <td>7.54</td>\n",
       "      <td>9.93</td>\n",
       "      <td>17.52</td>\n",
       "      <td>10.41</td>\n",
       "      <td>26.83</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MW   AMW     Sv     Se     Sp     Ss    Mv    Me    Mp  \\\n",
       "aroma_molecule_id                                                               \n",
       "6309               154.28  5.32  15.89  28.28  17.31  24.92  0.55  0.98  0.60   \n",
       "7794               152.16  8.01  11.93  19.52  12.41  31.50  0.63  1.03  0.65   \n",
       "2767               122.18  6.43  11.50  18.75  12.26  20.67  0.61  0.99  0.65   \n",
       "3365               102.15  6.01   9.01  17.07   9.72  21.50  0.53  1.00  0.57   \n",
       "3733               128.14  7.54   9.93  17.52  10.41  26.83  0.58  1.03  0.61   \n",
       "\n",
       "                     Ms  ...  Neoplastic-80  Neoplastic-50  Infective-80  \\\n",
       "aroma_molecule_id        ...                                               \n",
       "6309               2.27  ...              0              0             1   \n",
       "7794               2.86  ...              0              0             0   \n",
       "2767               2.30  ...              0              0             0   \n",
       "3365               3.07  ...              0              0             0   \n",
       "3733               2.98  ...              0              0             0   \n",
       "\n",
       "                   Infective-50  BLTF96  BLTD48  BLTA96  ALOGPS_logP  \\\n",
       "aroma_molecule_id                                                      \n",
       "6309                          0   -3.64   -3.83   -3.87         2.68   \n",
       "7794                          0   -2.17   -2.20   -2.15         1.31   \n",
       "2767                          0   -3.03   -3.15   -3.15         1.51   \n",
       "3365                          0   -2.24   -2.27   -2.23         1.26   \n",
       "3733                          0   -0.73   -0.58   -0.46        -0.33   \n",
       "\n",
       "                   ALOGPS_logS  Slope  \n",
       "aroma_molecule_id                      \n",
       "6309                     -2.51    NaN  \n",
       "7794                     -1.48    NaN  \n",
       "2767                     -1.03    NaN  \n",
       "3365                     -0.20    NaN  \n",
       "3733                      0.54    NaN  \n",
       "\n",
       "[5 rows x 1667 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dragon_df = pd.read_csv('dragon data of available SMILES.csv', sep=';', header=0, decimal=',')\\\n",
    "    .set_index('aroma_molecule_id')\n",
    "\n",
    "slope_df = pd.read_csv('ratio_vs_power.txt', sep='\\t', header=0)\n",
    "slope_df.rename({' MoleculeId': 'MoleculeId'}, axis=1, inplace=True)\n",
    "slope_df.set_index('MoleculeId', inplace=True)\n",
    "\n",
    "dragon_data = dragon_df.join(slope_df, how='left')\n",
    "dragon_data.drop(['MoleculeName', 'CAS', 'CanonicalSMILES', 'MOL_ID'], axis=1, inplace=True)\n",
    "dragon_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23dd6657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MW             160.593521\n",
       "AMW              6.401521\n",
       "Sv              15.272239\n",
       "Se              26.557896\n",
       "Sp              16.581788\n",
       "                  ...    \n",
       "BLTD48          -3.614613\n",
       "BLTA96          -3.645241\n",
       "ALOGPS_logP      3.700424\n",
       "ALOGPS_logS     -1.984430\n",
       "Slope            0.693550\n",
       "Length: 1667, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dragon_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee63cafe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature0       160.593521\n",
       "Feature1         6.401521\n",
       "Feature2        15.272239\n",
       "Feature3        26.557896\n",
       "Feature4        16.581788\n",
       "                  ...    \n",
       "Feature1662     -3.614613\n",
       "Feature1663     -3.645241\n",
       "Feature1664      3.700424\n",
       "Feature1665     -1.984430\n",
       "Target           0.693550\n",
       "Length: 1667, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13eba04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature1657</th>\n",
       "      <th>Feature1658</th>\n",
       "      <th>Feature1659</th>\n",
       "      <th>Feature1660</th>\n",
       "      <th>Feature1661</th>\n",
       "      <th>Feature1662</th>\n",
       "      <th>Feature1663</th>\n",
       "      <th>Feature1664</th>\n",
       "      <th>Feature1665</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>154.28</td>\n",
       "      <td>5.32</td>\n",
       "      <td>15.89</td>\n",
       "      <td>28.28</td>\n",
       "      <td>17.31</td>\n",
       "      <td>24.92</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>152.16</td>\n",
       "      <td>8.01</td>\n",
       "      <td>11.93</td>\n",
       "      <td>19.52</td>\n",
       "      <td>12.41</td>\n",
       "      <td>31.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>122.18</td>\n",
       "      <td>6.43</td>\n",
       "      <td>11.50</td>\n",
       "      <td>18.75</td>\n",
       "      <td>12.26</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>102.15</td>\n",
       "      <td>6.01</td>\n",
       "      <td>9.01</td>\n",
       "      <td>17.07</td>\n",
       "      <td>9.72</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>128.14</td>\n",
       "      <td>7.54</td>\n",
       "      <td>9.93</td>\n",
       "      <td>17.52</td>\n",
       "      <td>10.41</td>\n",
       "      <td>26.83</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "Id                                                                           \n",
       "6309    154.28      5.32     15.89     28.28     17.31     24.92      0.55   \n",
       "7794    152.16      8.01     11.93     19.52     12.41     31.50      0.63   \n",
       "2767    122.18      6.43     11.50     18.75     12.26     20.67      0.61   \n",
       "3365    102.15      6.01      9.01     17.07      9.72     21.50      0.53   \n",
       "3733    128.14      7.54      9.93     17.52     10.41     26.83      0.58   \n",
       "\n",
       "      Feature7  Feature8  Feature9  ...  Feature1657  Feature1658  \\\n",
       "Id                                  ...                             \n",
       "6309      0.98      0.60      2.27  ...            0            0   \n",
       "7794      1.03      0.65      2.86  ...            0            0   \n",
       "2767      0.99      0.65      2.30  ...            0            0   \n",
       "3365      1.00      0.57      3.07  ...            0            0   \n",
       "3733      1.03      0.61      2.98  ...            0            0   \n",
       "\n",
       "      Feature1659  Feature1660  Feature1661  Feature1662  Feature1663  \\\n",
       "Id                                                                      \n",
       "6309            1            0        -3.64        -3.83        -3.87   \n",
       "7794            0            0        -2.17        -2.20        -2.15   \n",
       "2767            0            0        -3.03        -3.15        -3.15   \n",
       "3365            0            0        -2.24        -2.27        -2.23   \n",
       "3733            0            0        -0.73        -0.58        -0.46   \n",
       "\n",
       "      Feature1664  Feature1665  Target  \n",
       "Id                                      \n",
       "6309         2.68        -2.51     NaN  \n",
       "7794         1.31        -1.48     NaN  \n",
       "2767         1.51        -1.03     NaN  \n",
       "3365         1.26        -0.20     NaN  \n",
       "3733        -0.33         0.54     NaN  \n",
       "\n",
       "[5 rows x 1667 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [f'Feature{i}' for i in range(dragon_data.shape[1]-1)]\n",
    "features.append('Target')\n",
    "features = pd.Series(features)\n",
    "dragon_data.columns = features\n",
    "dragon_data.index.names = ['Id']\n",
    "print(dragon_data.equals(all_data))\n",
    "dragon_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62882b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dragon_data.compare(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989c2f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature0       160.593521\n",
       "Feature1         6.401521\n",
       "Feature2        15.272239\n",
       "Feature3        26.557896\n",
       "Feature4        16.581788\n",
       "                  ...    \n",
       "Feature1662     -3.614613\n",
       "Feature1663     -3.645241\n",
       "Feature1664      3.700424\n",
       "Feature1665     -1.984430\n",
       "Target           0.693550\n",
       "Length: 1667, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dragon_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285ea11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature0       160.593521\n",
       "Feature1         6.401521\n",
       "Feature2        15.272239\n",
       "Feature3        26.557896\n",
       "Feature4        16.581788\n",
       "                  ...    \n",
       "Feature1662     -3.614613\n",
       "Feature1663     -3.645241\n",
       "Feature1664      3.700424\n",
       "Feature1665     -1.984430\n",
       "Target           0.693550\n",
       "Length: 1667, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97031b83",
   "metadata": {},
   "source": [
    "## 0.3 Extract modelling DataFrame\n",
    "\n",
    "The modelling goal concerns only the lines in all_data where the Target column is not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26f53e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub data shape: (8, 1667)\n",
      "All data shape: (4524, 1667)\n",
      "All data with non-null Target shape: (8, 1667)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature1657</th>\n",
       "      <th>Feature1658</th>\n",
       "      <th>Feature1659</th>\n",
       "      <th>Feature1660</th>\n",
       "      <th>Feature1661</th>\n",
       "      <th>Feature1662</th>\n",
       "      <th>Feature1663</th>\n",
       "      <th>Feature1664</th>\n",
       "      <th>Feature1665</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>116.18</td>\n",
       "      <td>5.81</td>\n",
       "      <td>10.61</td>\n",
       "      <td>19.96</td>\n",
       "      <td>11.48</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.6824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>144.24</td>\n",
       "      <td>5.55</td>\n",
       "      <td>13.81</td>\n",
       "      <td>25.72</td>\n",
       "      <td>15.00</td>\n",
       "      <td>23.67</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>2.92</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>0.7372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187</th>\n",
       "      <td>130.21</td>\n",
       "      <td>5.66</td>\n",
       "      <td>12.21</td>\n",
       "      <td>22.84</td>\n",
       "      <td>13.24</td>\n",
       "      <td>22.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.86</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>2.36</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>0.7479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>136.26</td>\n",
       "      <td>5.24</td>\n",
       "      <td>14.78</td>\n",
       "      <td>25.07</td>\n",
       "      <td>16.09</td>\n",
       "      <td>16.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.26</td>\n",
       "      <td>-4.53</td>\n",
       "      <td>-4.60</td>\n",
       "      <td>3.66</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>0.2584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>100.18</td>\n",
       "      <td>5.27</td>\n",
       "      <td>10.10</td>\n",
       "      <td>18.63</td>\n",
       "      <td>11.02</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>1.69</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.5759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>192.33</td>\n",
       "      <td>5.66</td>\n",
       "      <td>19.49</td>\n",
       "      <td>33.16</td>\n",
       "      <td>21.07</td>\n",
       "      <td>29.75</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.94</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>4.11</td>\n",
       "      <td>-3.27</td>\n",
       "      <td>0.7274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>136.16</td>\n",
       "      <td>7.56</td>\n",
       "      <td>11.41</td>\n",
       "      <td>18.19</td>\n",
       "      <td>11.95</td>\n",
       "      <td>25.83</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>1.64</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>1.2339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>116.18</td>\n",
       "      <td>5.81</td>\n",
       "      <td>10.61</td>\n",
       "      <td>19.96</td>\n",
       "      <td>11.48</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>1.84</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>0.5853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "Id                                                                           \n",
       "5605    116.18      5.81     10.61     19.96     11.48     20.67      0.53   \n",
       "5637    144.24      5.55     13.81     25.72     15.00     23.67      0.53   \n",
       "6187    130.21      5.66     12.21     22.84     13.24     22.50      0.53   \n",
       "7891    136.26      5.24     14.78     25.07     16.09     16.58      0.57   \n",
       "623     100.18      5.27     10.10     18.63     11.02     16.50      0.53   \n",
       "3503    192.33      5.66     19.49     33.16     21.07     29.75      0.57   \n",
       "3837    136.16      7.56     11.41     18.19     11.95     25.83      0.63   \n",
       "4714    116.18      5.81     10.61     19.96     11.48     20.67      0.53   \n",
       "\n",
       "      Feature7  Feature8  Feature9  ...  Feature1657  Feature1658  \\\n",
       "Id                                  ...                             \n",
       "5605      1.00      0.57      2.58  ...            0            0   \n",
       "5637      0.99      0.58      2.37  ...            0            0   \n",
       "6187      0.99      0.58      2.50  ...            0            0   \n",
       "7891      0.96      0.62      1.66  ...            0            0   \n",
       "623       0.98      0.58      2.36  ...            0            0   \n",
       "3503      0.98      0.62      2.13  ...            1            0   \n",
       "3837      1.01      0.66      2.58  ...            0            0   \n",
       "4714      1.00      0.57      2.58  ...            0            0   \n",
       "\n",
       "      Feature1659  Feature1660  Feature1661  Feature1662  Feature1663  \\\n",
       "Id                                                                      \n",
       "5605            0            0        -2.56        -2.62        -2.60   \n",
       "5637            0            0        -3.14        -3.28        -3.29   \n",
       "6187            0            0        -2.86        -2.96        -2.96   \n",
       "7891            0            0        -4.26        -4.53        -4.60   \n",
       "623             0            0        -2.62        -2.69        -2.67   \n",
       "3503            1            0        -3.94        -4.17        -4.23   \n",
       "3837            0            0        -2.66        -2.74        -2.72   \n",
       "4714            0            0        -2.56        -2.62        -2.60   \n",
       "\n",
       "      Feature1664  Feature1665  Target  \n",
       "Id                                      \n",
       "5605         1.80        -0.99  0.6824  \n",
       "5637         2.92        -2.09  0.7372  \n",
       "6187         2.36        -1.80  0.7479  \n",
       "7891         3.66        -2.94  0.2584  \n",
       "623          1.69        -0.79  0.5759  \n",
       "3503         4.11        -3.27  0.7274  \n",
       "3837         1.64        -1.90  1.2339  \n",
       "4714         1.84        -1.31  0.5853  \n",
       "\n",
       "[8 rows x 1667 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data with target value\n",
    "target_data = all_data[all_data.Target.notnull()]\n",
    "\n",
    "# Sanity check\n",
    "print(f'Sub data shape: {target_data.shape}')\n",
    "print(f'All data shape: {all_data.shape}')\n",
    "print(f'All data with non-null Target shape: {all_data[all_data.Target.notnull()].shape}')\n",
    "all_data[all_data.Target.notnull()].head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cce81d",
   "metadata": {},
   "source": [
    "# 1. Data exploration\n",
    "\n",
    "## 1.1 Feature dropping\n",
    "\n",
    "Given the very large number of features, visualisation is difficult or would be overly lengthy. However, some features can already be dropped at this stage:\n",
    "* Any feature that is null in the sub dataset can be removed from datasets since it will bring no information for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feafbac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature1545    8\n",
       "Feature1580    8\n",
       "Feature1605    8\n",
       "Feature1613    8\n",
       "Feature1614    8\n",
       "Feature1621    8\n",
       "Feature1622    8\n",
       "Feature1623    8\n",
       "Feature1624    8\n",
       "Feature1625    8\n",
       "Feature1626    8\n",
       "Feature1627    8\n",
       "Feature1628    8\n",
       "Feature1629    8\n",
       "Feature1630    8\n",
       "Feature1631    8\n",
       "Feature1632    8\n",
       "Feature1633    8\n",
       "Feature1634    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missingness in target_data\n",
    "target_data.isnull().sum()[target_data.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9cb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for features that are missing\n",
    "for feature in target_data.columns:\n",
    "    if target_data[feature].isnull().sum() > 0:\n",
    "        # Remove feature from both datasets\n",
    "        target_data.drop(feature, axis=1, inplace=True)\n",
    "        all_data.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc95e1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck missingness after feature deletion\n",
    "target_data.isnull().sum()[target_data.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b35e523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature279      27\n",
       "Feature280      27\n",
       "Feature281      27\n",
       "Feature282      27\n",
       "Feature283      27\n",
       "Feature284      50\n",
       "Feature285      50\n",
       "Feature286      50\n",
       "Feature287      50\n",
       "Feature288      50\n",
       "Feature289     101\n",
       "Feature290     101\n",
       "Feature291     101\n",
       "Feature292     101\n",
       "Feature293     101\n",
       "Target        4516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all_data missingness after feature deletion\n",
    "all_data.isnull().sum()[all_data.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92beccf8",
   "metadata": {},
   "source": [
    "## 1.2 Target data\n",
    "\n",
    "A cursory exploration of the target values can be performed at this stage. Selected features will be explored visually after data cleaning. The targets provided are quite similar, between 0.5 and 0.8, except for two samples for which they are significantly different, around 0.3 and 1.2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c9a5985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check distribution of available targets\n",
    "sns.histplot(data=target_data, x='Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38fbdab",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning\n",
    "\n",
    "Data cleaning can include several steps. Each of these steps is tackled sequentially.\n",
    "* Data Correction\n",
    "* Data Completion\n",
    "* Data Creation\n",
    "* Data Conversion\n",
    "\n",
    "## 2.1 Data Correction\n",
    "\n",
    "Since the dataset provided was extracted from a single database, it is assumed there is no further missing data than the entries that were flagged as \"#N/A\" and converted automatically to np.nan by pd.read_csv. Any sparse features for which most values are 0 will be assumed to be correct (it will be assumed that 0 is an actual value and not a placeholder for missing data). No Data Correction is therefore required for this dataset.\n",
    "\n",
    "## 2.2 Data Completion\n",
    "\n",
    "After dropping features for which all values are null in the sub_data dataset (see step 1.1), there only remain missing values in the all_data dataset. Since this dataset is less critical than sub_data, these values will be imputed using a simple median imputer as to not assume the distribution of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e7c4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get numerical features of all_data\n",
    "numericals = all_data.select_dtypes(include=np.number).columns.to_list()\n",
    "\n",
    "# Apply SimpleImputer to numerical features in all_data\n",
    "si = SimpleImputer(strategy='median', copy=True)\n",
    "all_data[numericals] = si.fit_transform(all_data[numericals])\n",
    "\n",
    "# Check missingness after imputing\n",
    "all_data.isnull().sum()[all_data.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439977d",
   "metadata": {},
   "source": [
    "## 2.3 Data Creation\n",
    "\n",
    "Given the large number of features, no new features will be created from the data, at least at this point. Feature reduction techniques will be used further in the project to reduce the dimensionality of the problem.\n",
    "\n",
    "## 2.4 Data Conversion\n",
    "\n",
    "Some models only accept numerical parameters as input, and any categorical or boolean features should then be converted to numeric features, e.g. using pd.get_dummies. As can be seen below, there are no non-numeric predictors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52ba70c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check non-numeric columns in all_data\n",
    "non_numeric = all_data.select_dtypes(exclude=np.number).columns.to_list()\n",
    "print(non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b87c1",
   "metadata": {},
   "source": [
    "# 3. Visual exploration\n",
    "\n",
    "Visual exploration was performed as part of this project. However, visual exploration requires having knowledge on the features, targets and samples which is not provided in this anonymised dataset. For this reason, this section is removed from this public notebook.\n",
    "\n",
    "Visual exploration included scatter plots and KDE plots of selected features expected to have an impact on the target value to assess whether relations were already visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdab414",
   "metadata": {},
   "source": [
    "# ----------------------\n",
    "# Modelling strategy\n",
    "# ----------------------\n",
    "\n",
    "## On fitting with a large number of parameters\n",
    "\n",
    "In this problem, we have 8 data points, and over 1600 possible predictors: just like it is possible to fit any curve by increasing the order of the equation (and thus the number of parameters), we could fit this dataset almost to perfection by tuning and optimising the 1600 parameters we have at our disposal, the weights of each predictor. However, such a model, while extremely efficient at reproducing measured data, would perform very poorly when applied for prediction of the target value for new samples, and would furthermore not bring any explainability. This is not a requirement of the current problem, but it is a direct result of the lack of meaning this model would have, just like a 1600th order polynomial.\n",
    "\n",
    "The best model is generally the simplest model that manages to capture the true variability in the data, without capturing the noise. This could be measurement uncertainty, personal preferences, ... Depending on the application.\n",
    "\n",
    "As a result, the goal of this problem should not be to fit as best as possible, but rather to find the simplest model that is able to capture its variance without its very specific particularities. Aka, avoid overfitting.\n",
    "\n",
    "## On overfitting in small samples\n",
    "\n",
    "This being said, it is highly likely that any model we obtain would be overfit because we have only 8 data points. In addition, along these data points, we have half of the samples that are very similar, and the other half that each have their own specifics \\[Not shown part of the visual exploration of section 3\\]. Furthermore, two of the samples exhibit what we could call at this scale outlier targets. Therefore, even using cross validation means any model not trained to these specifics will be very poor at predicting their targets, but most models should be able to predict the targets of the 4 similar samples.\n",
    "\n",
    "If the dimensionality of the problem is its challenge, its limitation is sampling. A model can only perform well if it had been fitted, or trained, using a sample that is representative of the population. Here, this is certainly not the case as the full database (what we could consider the population in this case) contains over 4500 \"lines\" of predictors.\n",
    "\n",
    "In conclusion, any model we build will be overfit to the samples compared to unseen samples, and the goal of the assignment cannot be predicting new target values because of this.\n",
    "\n",
    "## On not using train_test_split\n",
    "\n",
    "Given the small size and more importantly the diversity of the samples contained in the dataset, the dataset will not be split for this modelling exercise, e.g. using sklearn's train_test_split function. The reasoning behind this take is take is that every sample in the dataset is valuable for building the model since in most cases only 1 of the samples contains certain peculiarities.\n",
    "\n",
    "## On the metric used for model performance\n",
    "\n",
    "Since train_test_split will not be used, a different metric for model selection is used: the mean absolute error resulting from 8-fold cross-validation of each model using sklearn's cross_val_score. Computing 8-fold cross-validation on a sample size of 8 comes down to fitting the model using 7 out of the 8 samples 8 times, each time leaving out a different sample and calculating the absolute error on the prediction for the left-out sample. The mean of these 8 mean absolute errors is taken as an indicator of the ability of the model to have captured most of the variance provided in the sample without overfitting the pecularities of the 8 specific ones provided.\n",
    "\n",
    "# 4. Baseline model\n",
    "\n",
    "As a reference standard, a baseline model is fitted using all features. Since the target is a continuous numerical value, linear regression is used as a baseline model. As discussed above, this model will be severely overfitted to the data.\n",
    "\n",
    "## 4.1 DataFrame formatting for modelling\n",
    "\n",
    "Before fitting, the data is transformed to be ready for modelling.\n",
    "* The X DataFrame contains all predictors, i.e. target_data\n",
    "* The y DataFrame contains the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31cf110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = target_data.drop(['Target'], axis=1, inplace=False)\n",
    "y = target_data.Target\n",
    "\n",
    "# Reproduce sample order compared to uncensored dataset for robustness\n",
    "X = X.reindex(index=[3837, 6187, 5637, 3503, 5605, 4714, 623, 7891])\n",
    "y = y.reindex(index=[3837, 6187, 5637, 3503, 5605, 4714, 623, 7891])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019619c",
   "metadata": {},
   "source": [
    "Eech model will follow the same structure:\n",
    "* Initialisation of the different tools\n",
    "* Fitting\n",
    "* Predicting\n",
    "* Computing metrics (model MAE and 8-fold cross-validation MAE)\n",
    "\n",
    "## 4.2 Simple linear regression\n",
    "\n",
    "As expected, given the large number of predictors provided, the prediction is practically exact. It is highly likely that such a model is severely overfitted to the 8 examples provided. This is confirmed by the very low model MAE and the very high CV average MAE obtained of roughly 0.78."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3c88d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            MAE CV_MAE\n",
      "model                 \n",
      "lr     9.58e-16   0.78\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "name_lr = 'lr'\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fitting\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predicting\n",
    "preds = lr.predict(X)\n",
    "\n",
    "# Metrics - MAE\n",
    "mae_lr = mean_absolute_error(y, preds)\n",
    "\n",
    "# Metrics - CV\n",
    "cv_results = cross_val_score(lr, X, y, cv=8, scoring='neg_mean_absolute_error')\n",
    "cv_lr = abs(cv_results).mean()\n",
    "\n",
    "# Format metrics\n",
    "metrics_lr = np.array([name_lr,'{:0.2e}'.format(mae_lr), '{:.2f}'.format(cv_lr)]).reshape((1, 3))\n",
    "\n",
    "# Combine metrics in single df\n",
    "metrics = pd.DataFrame(metrics_lr, columns=['model', 'MAE', 'CV_MAE']).set_index('model')\n",
    "\n",
    "# Show results\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76cb50",
   "metadata": {},
   "source": [
    "## 4.3 Standardised simple linear regression\n",
    "\n",
    "A StandardScaler is also used to normalize feature mean and standard deviation since linear regression models tend to be influenced by features on differring scales. Using the StandardScaler before simple linear regression significantly improves the CV MAE (by about twofold). However, the model remain severely overfitted since it still uses all predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de5a220f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MAE CV_MAE\n",
      "model                  \n",
      "lr      9.58e-16   0.78\n",
      "lr_std  2.43e-16   0.32\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "name_lr_std = 'lr_std'\n",
    "ss = StandardScaler()\n",
    "lr_std = LinearRegression()\n",
    "pipeline = Pipeline([('scaler', ss), ('linear_regression', lr_std)])\n",
    "\n",
    "# Fitting\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predicting\n",
    "preds_std = pipeline.predict(X)\n",
    "\n",
    "# Metrics - MAE\n",
    "mae_lr_std = mean_absolute_error(y, preds_std)\n",
    "\n",
    "# Metrics - CV\n",
    "cv_results_std = cross_val_score(pipeline, X, y, cv=8, scoring='neg_mean_absolute_error')\n",
    "cv_lr_std = abs(cv_results_std).mean()\n",
    "\n",
    "# Format metrics\n",
    "metrics_lr_std = np.array([name_lr_std,'{:0.2e}'.format(mae_lr_std), '{:.2f}'.format(cv_lr_std)]).reshape((1, 3))\n",
    "\n",
    "# Combine metrics in single df\n",
    "if name_lr_std not in metrics.index:\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(metrics_lr_std, columns=['model', 'MAE', 'CV_MAE']).set_index('model')],\n",
    "                        axis=0)\n",
    "\n",
    "# Show results\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc9300",
   "metadata": {},
   "source": [
    "## 4.4 Most important features without feature selection\n",
    "\n",
    "Even though all descriptors were used in this baseline model, we can already get an idea of which features played a major role by examining the model coefficients. Note that we do not find any of the features we intuitively thought would be important in these top features \\[Features were anonymised here, their interpretation is kept for reference\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a623824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lr       lr_std\n",
      "0   Feature185     Feature5\n",
      "1    Feature66   Feature875\n",
      "2    Feature88   Feature815\n",
      "3    Feature77   Feature755\n",
      "4    Feature64   Feature429\n",
      "5    Feature86   Feature845\n",
      "6   Feature116   Feature278\n",
      "7   Feature692  Feature1287\n",
      "8   Feature691   Feature785\n",
      "9    Feature80     Feature4\n",
      "10  Feature667   Feature414\n",
      "11  Feature689   Feature399\n",
      "12  Feature755  Feature1105\n",
      "13  Feature597  Feature1285\n",
      "14  Feature845  Feature1143\n",
      "15  Feature595  Feature1061\n",
      "16  Feature754   Feature998\n",
      "17  Feature255  Feature1094\n",
      "18  Feature750   Feature369\n",
      "19  Feature844   Feature377\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame containing coefficients\n",
    "coeffs = pd.DataFrame(zip(lr.coef_, lr_std.coef_),\n",
    "                      columns=['Coefficients_lr', 'Coefficients_lr_std'],\n",
    "                      index=X.columns)\n",
    "\n",
    "# Get feature importance\n",
    "coeffs['AbsCoefficients_lr'] = abs(coeffs.Coefficients_lr)\n",
    "coeffs['AbsCoefficients_lr_std'] = abs(coeffs.Coefficients_lr_std)\n",
    "\n",
    "# Get top features for both models\n",
    "lr_important_features = coeffs.sort_values(by='AbsCoefficients_lr', ascending=False).head(20).index\n",
    "lr_std_important_features = coeffs.sort_values(by='AbsCoefficients_lr_std', ascending=False).head(20).index\n",
    "\n",
    "# Create DataFrame of top features\n",
    "important_features = pd.DataFrame(zip(lr_important_features, lr_std_important_features),\n",
    "                                  columns=['lr', 'lr_std'])\n",
    "\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a84f83",
   "metadata": {},
   "source": [
    "# 5. Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40bfb9a",
   "metadata": {},
   "source": [
    "As discussed above, the goal of the exercise is to find the \"best simplest model\" to fit the targets. To that objective, two dimensionality reduction strategies will be explored: Principal Components Analysis (PCA) for performing feature reduction, and penalized regression using LASSO for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6230dbd",
   "metadata": {},
   "source": [
    "## 5.1 PCA\n",
    "\n",
    "### Exploratory PCA\n",
    "\n",
    "First, the data is scaled and transformed using PCA to determine how many Principal Components (PC) capture most of the variability.\n",
    "\n",
    "The StandardScaler is used since PCA is very sensitive to feature scale. Using PCA to perform dimensionality reduction on the target dataset (containing values for 8 samples) shows that >95% of the variance in the data can be captured by the 5 first principal components, while the 4 first components capture >90% of the variance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10109fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of variance captured cumulatively by including more principal components:\n",
      " [0.43 0.67 0.83 0.91 0.96 0.98 0.99 0.99]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore PCA: scale the data and create 8 principal components using PCA\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Fit maximum number of PCs\n",
    "pca_expl = PCA(n_components=X_scaled.shape[0])\n",
    "pca_features = pca_expl.fit_transform(X_scaled)\n",
    "\n",
    "# Print cumulative sum of relative importance\n",
    "print('% of variance captured cumulatively by including more principal components:\\n',\n",
    "      (pca_expl.explained_variance_/pca_expl.explained_variance_.sum()).round(2).cumsum())\n",
    "\n",
    "# Plot relative variance explained by each added PCA feature and Pareto\n",
    "plt.bar(range(pca_expl.n_components_), pca_expl.explained_variance_/pca_expl.explained_variance_.sum())\n",
    "plt.plot((pca_expl.explained_variance_/pca_expl.explained_variance_.sum()).cumsum(), color='green')\n",
    "plt.axhline(y=.95, color='red', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=4, color='red', linestyle='--', linewidth=1)\n",
    "plt.title('Principal Component feature importance')\n",
    "plt.ylabel('Relative variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c34450",
   "metadata": {},
   "source": [
    "### Linear regression with 5 principal components\n",
    "\n",
    "The result from the linear regression applying PCA wth 5 principal components is still very good at fitting the 8 targets provided, with a mean absolute target difference of 0.03. Cross-validation does not show significant improvement over the scaled simple linear regression.\n",
    "\n",
    "The downside of using PCA is the loss of explainability of the observed relations, the most important features are therefore not explored as they were in the simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9256514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MAE CV_MAE\n",
      "model                  \n",
      "lr      9.58e-16   0.78\n",
      "lr_std  2.43e-16   0.32\n",
      "lr_pca  2.94e-02   0.31\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "name_pca = 'lr_pca'\n",
    "ss_pca = StandardScaler()\n",
    "pca = PCA(n_components=5) # 5 components capture 95% of variance, see PCA exploration above\n",
    "lr_pca = LinearRegression()\n",
    "pipeline_pca = Pipeline([('scaler', ss_pca), ('pca', pca), ('linear_regression', lr_pca)])\n",
    "\n",
    "# Fitting\n",
    "pipeline_pca.fit(X, y)\n",
    "\n",
    "# Predicting\n",
    "preds_pca = pipeline_pca.predict(X)\n",
    "\n",
    "# Metrics - MAE\n",
    "mae_pca = mean_absolute_error(y, preds_pca)\n",
    "\n",
    "# Metrics - CV\n",
    "cv_results_pca = cross_val_score(pipeline_pca, X, y, cv=8, scoring='neg_mean_absolute_error')\n",
    "cv_pca = abs(cv_results_pca).mean()\n",
    "\n",
    "# Format metrics\n",
    "metrics_pca = np.array([name_pca,'{:0.2e}'.format(mae_pca), '{:.2f}'.format(cv_pca)]).reshape((1, 3))\n",
    "\n",
    "# Combine metrics in single df\n",
    "if name_pca not in metrics.index:\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(metrics_pca, columns=['model', 'MAE', 'CV_MAE']).set_index('model')],\n",
    "                        axis=0)\n",
    "\n",
    "# Show results\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2a99d",
   "metadata": {},
   "source": [
    "## 5.2 PCA using entire Feature dataset\n",
    "\n",
    "Given the results observed in the previous section (no real difference between scaled linear regression using all features and scaled linear regression using PCA features), it will next be attempted to apply PCA to the ~4500 samples of the full feature dataset to extract variability, then apply these new principal components to the target dataset to assess whether this improves the results. The main idea behind this attempt is that the true variance may better be captured using more samples of the features, even if their target is unknown.\n",
    "\n",
    "To do so, the all_data DataFrame is split in a similar fashion to the target_data DF, to extract the feature DataFrame X_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06454d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = all_data.drop(['Target'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f77f49",
   "metadata": {},
   "source": [
    "### Exploratory PCA\n",
    "\n",
    "Over 95% of the variance is captured by including 160 principal components. However, we could achieve capturing >90% of variance by taking significantly less principal components, 95 in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d4862b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore PCA: scale the data and create principal components using PCA\n",
    "X_all_scaled = StandardScaler().fit_transform(X_all)\n",
    "\n",
    "# Fit maximum number of PCs\n",
    "pca_all_expl = PCA(n_components=min(X_all_scaled.shape))\n",
    "pca_all_features = pca_all_expl.fit_transform(X_all_scaled)\n",
    "\n",
    "# Plot relative variance explained by each added PCA feature and Pareto\n",
    "plt.bar(range(pca_all_expl.n_components_), pca_all_expl.explained_variance_/pca_all_expl.explained_variance_.sum())\n",
    "plt.plot((pca_all_expl.explained_variance_/pca_all_expl.explained_variance_.sum()).cumsum(), color='green')\n",
    "plt.axhline(y=.95, color='red', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=160, color='red', linestyle='--', linewidth=1)\n",
    "plt.title('Principal Component feature importance (zoom)')\n",
    "plt.ylabel('Relative variance')\n",
    "plt.xlabel('Principal Component')\n",
    "# Zoom in on intersect region\n",
    "plt.xlim([80, 200])\n",
    "plt.ylim([.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a681c26",
   "metadata": {},
   "source": [
    "### Linear regression using PCs of all Feature samples\n",
    "\n",
    "This strategy made the cross-validation score much worse, on the same level os the non-standardised simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e7df5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 MAE CV_MAE\n",
      "model                      \n",
      "lr          9.58e-16   0.78\n",
      "lr_std      2.43e-16   0.32\n",
      "lr_pca      2.94e-02   0.31\n",
      "lr_pca_all  2.86e-02   0.72\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "name_pca_all = 'lr_pca_all'\n",
    "ss_pca_all = StandardScaler()\n",
    "pca_all = PCA(n_components=160)\n",
    "lr_pca_all = LinearRegression()\n",
    "\n",
    "# Fitting\n",
    "# No pipeline is used since we apply the PC transformation fitted on all samples (X_all)\n",
    "# to the 8 samples for which a target is provided (X)\n",
    "pca_all.fit(ss_pca_all.fit_transform(X_all))\n",
    "X_pca_allMols = pca.transform(ss_pca_all.transform(X))\n",
    "lr.fit(X_pca_allMols, y)\n",
    "\n",
    "# Predicting\n",
    "preds_pca_all = lr.predict(X_pca_allMols)\n",
    "\n",
    "# Metrics - MAE\n",
    "mae_pca_all = mean_absolute_error(y, preds_pca_all)\n",
    "\n",
    "# Metrics - CV\n",
    "cv_results_pca_all = cross_val_score(lr, X_pca_allMols, y, cv=8, scoring='neg_mean_absolute_error')\n",
    "cv_pca_all = abs(cv_results_pca_all).mean()\n",
    "\n",
    "# Format metrics\n",
    "metrics_pca_all = np.array([name_pca_all,'{:0.2e}'.format(mae_pca_all), '{:.2f}'.format(cv_pca_all)]).reshape((1, 3))\n",
    "\n",
    "# Combine metrics in single df\n",
    "if name_pca_all not in metrics.index:\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(metrics_pca_all, columns=['model', 'MAE', 'CV_MAE']).set_index('model')],\n",
    "                        axis=0)\n",
    "\n",
    "# Show results\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955fad3",
   "metadata": {},
   "source": [
    "## 5.3 LASSO regression\n",
    "\n",
    "There are two main regularization techniques for linear regression, called L1 and L2 regularization. By applying different penalization terms to the regression loss function, they aim at avoiding overfitting the model to the fitted dataset. The strategy applied is different for both regularization schemes. The end result:\n",
    "* Under L1 regularization, the amplitude of the least important features weights is forced to 0 to avoid overfitting\n",
    "* Under L2 regularization, the amplitude of all feature weights is scaled down to avoid overfitting\n",
    "\n",
    "This means that among both regularization schemes, only L1 regularization performs feature selection. L1 regularization is the scheme implemented in the LASSO regressor (L2 regularization being implemented in Ridge regression). LASSO (Least Absolute Shrinkage and Selection Operator) regression will therefore be used to reduce the dimensionality of the problem and avoid overfitting.\n",
    "\n",
    "### 5.3.1. Baseline LASSO model\n",
    "\n",
    "The baseline LASSO model significantly improves the cross-validation MAE, but there still is an order of magnitude difference between the cross-validation MAE and the model MAE, which indicates that the model is still overfitted to the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e676533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 MAE CV_MAE\n",
      "model                      \n",
      "lr          9.58e-16   0.78\n",
      "lr_std      2.43e-16   0.32\n",
      "lr_pca      2.94e-02   0.31\n",
      "lr_pca_all  2.86e-02   0.72\n",
      "lasso       2.58e-02   0.16\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "name_lasso = 'lasso'\n",
    "lasso = Lasso()\n",
    "\n",
    "# Fitting\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Predicting\n",
    "preds_lasso = lasso.predict(X)\n",
    "\n",
    "# Metrics - MAE\n",
    "mae_lasso = mean_absolute_error(y, preds_lasso)\n",
    "\n",
    "# Metrics - CV\n",
    "cv_results_lasso = cross_val_score(lasso, X, y, cv=8, scoring='neg_mean_absolute_error')\n",
    "cv_lasso = abs(cv_results_lasso).mean()\n",
    "\n",
    "# Format metrics\n",
    "metrics_lasso = np.array([name_lasso,'{:0.2e}'.format(mae_lasso), '{:.2f}'.format(cv_lasso)]).reshape((1, 3))\n",
    "\n",
    "# Combine metrics in single df\n",
    "if name_lasso not in metrics.index:\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(metrics_lasso, columns=['model', 'MAE', 'CV_MAE']).set_index('model')],\n",
    "                        axis=0)\n",
    "\n",
    "# Show results\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b5c37",
   "metadata": {},
   "source": [
    "## 5.3.2 LASSO regression with standardisation\n",
    "\n",
    "Aplying the StandardScaler before the LASSO regressor decreases the cross-validation MAE, but this is the first model for which the model MAE (that can be associated with the training set error) and the cross-validation MAE (that can be associated with the test set error) are close. This indicates that the LASSO regressor with standardization is the \"best simplest model\" found so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a87a130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 MAE CV_MAE\n",
      "model                      \n",
      "lr          9.58e-16   0.78\n",
      "lr_std      2.43e-16   0.32\n",
      "lr_pca      2.94e-02   0.31\n",
      "lr_pca_all  2.86e-02   0.72\n",
      "lasso       2.58e-02   0.16\n",
      "lasso_std   1.68e-01   0.19\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "name_lasso_std = 'lasso_std'\n",
    "ss_lasso = StandardScaler()\n",
    "lasso_std = Lasso()\n",
    "pipeline_lasso_std = Pipeline([('scaler', ss_lasso), ('lasso', lasso_std)])\n",
    "\n",
    "# Fitting\n",
    "pipeline_lasso_std.fit(X, y)\n",
    "\n",
    "# Predicting\n",
    "preds_lasso_std = pipeline_lasso_std.predict(X)\n",
    "\n",
    "# Metrics - MAE\n",
    "mae_lasso_std = mean_absolute_error(y, preds_lasso_std)\n",
    "\n",
    "# Metrics - CV\n",
    "cv_results_lasso_std = cross_val_score(pipeline_lasso_std, X, y, cv=8, scoring='neg_mean_absolute_error')\n",
    "cv_lasso_std = abs(cv_results_lasso_std).mean()\n",
    "\n",
    "# Format metrics\n",
    "metrics_lasso_std = np.array([name_lasso_std,'{:0.2e}'.format(mae_lasso_std), '{:.2f}'.format(cv_lasso_std)]).reshape((1, 3))\n",
    "\n",
    "# Combine metrics in single df\n",
    "if name_lasso_std not in metrics.index:\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(metrics_lasso_std, columns=['model', 'MAE', 'CV_MAE']).set_index('model')],\n",
    "                        axis=0)\n",
    "\n",
    "# Show results\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a778a7",
   "metadata": {},
   "source": [
    "### 5.3.3 LASSO model feature importance\n",
    "\n",
    "The most important features of both LASSO models are examined in comparison with the linear models important features. The baseline LASSO model only keeps 4 coefficients above 0 among the > 1600 possible predictors.\n",
    "\n",
    "The standardised LASSO model shows only missing values. To check whether this is an error, the .coef_ and .intercept_ are examined below. From this check, it becomes clear that with standardised input predictors, the LASSO model sets all coefficients to 0 and only fits an intercept of roughly 0.69.\n",
    "\n",
    "As a result, the LASSO regressor predicts that the \"best simplest model\" is actually just a constant. This is not useful for interpretability physical understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98223de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lr       lr_std       lasso lasso_std\n",
      "0   Feature185     Feature5   Feature66       NaN\n",
      "1    Feature66   Feature875   Feature80       NaN\n",
      "2    Feature88   Feature815  Feature667       NaN\n",
      "3    Feature77   Feature755  Feature187       NaN\n",
      "4    Feature64   Feature429         NaN       NaN\n",
      "5    Feature86   Feature845         NaN       NaN\n",
      "6   Feature116   Feature278         NaN       NaN\n",
      "7   Feature692  Feature1287         NaN       NaN\n",
      "8   Feature691   Feature785         NaN       NaN\n",
      "9    Feature80     Feature4         NaN       NaN\n",
      "10  Feature667   Feature414         NaN       NaN\n",
      "11  Feature689   Feature399         NaN       NaN\n",
      "12  Feature755  Feature1105         NaN       NaN\n",
      "13  Feature597  Feature1285         NaN       NaN\n",
      "14  Feature845  Feature1143         NaN       NaN\n",
      "15  Feature595  Feature1061         NaN       NaN\n",
      "16  Feature754   Feature998         NaN       NaN\n",
      "17  Feature255  Feature1094         NaN       NaN\n",
      "18  Feature750   Feature369         NaN       NaN\n",
      "19  Feature844   Feature377         NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Initialize LASSO model names and link to regressor\n",
    "lasso_names = {'lasso': lasso,\n",
    "               'lasso_std': lasso_std}\n",
    "\n",
    "# Append LASSO most important features to DataFrame created previously for linear regression models\n",
    "for lasso_name in lasso_names:\n",
    "    \n",
    "    # Create temporary DataFrame with all feature importances for model\n",
    "    feature_df = pd.DataFrame({'Feature': X.columns,\n",
    "                              'Coefficient': lasso_names[lasso_name].coef_,\n",
    "                              'Importance': abs(lasso_names[lasso_name].coef_)})\n",
    "\n",
    "    # Avoid adding duplicate columns\n",
    "    if lasso_name not in important_features.columns:\n",
    "        # Add the most important non-null features of the LASSO model to the important_features df\n",
    "        important_features = pd.concat([important_features,\n",
    "                                        feature_df[feature_df.Importance > 0]\n",
    "                                            .sort_values(by='Importance', ascending=False)\n",
    "                                            .reset_index()\n",
    "                                            .Feature\n",
    "                                            .rename(lasso_name)],\n",
    "                                       axis=1)\n",
    "\n",
    "# See all important features for all models\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "033de05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all coefficient amplitudes = 0.0\n",
      "Standardised LASSO model intercept = 0.69355\n"
     ]
    }
   ],
   "source": [
    "print(f'Sum of all coefficient amplitudes = {lasso_std.coef_.sum()}')\n",
    "print(f'Standardised LASSO model intercept = {lasso_std.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed4d13",
   "metadata": {},
   "source": [
    "# 6. Hyperparameter tuning\n",
    "\n",
    "Since the \"best simplest model\" found so far turned out to be a constant \"model\", the LASSO regressor (that provided the best metrics so far) is further tuned to attempt to find a better model. Again, two models are fitted using a StandardScaler or not to assess its impact.\n",
    "\n",
    "## 6.1 Tuned LASSO regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e8b2477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LASSO parameters: {'alpha': 0.001, 'fit_intercept': False, 'max_iter': 100, 'normalize': True, 'tol': 0.1}\n",
      "                  MAE CV_MAE\n",
      "model                       \n",
      "lr           9.58e-16   0.78\n",
      "lr_std       2.43e-16   0.32\n",
      "lr_pca       2.94e-02   0.31\n",
      "lr_pca_all   2.86e-02   0.72\n",
      "lasso        2.58e-02   0.16\n",
      "lasso_std    1.68e-01   0.19\n",
      "lasso_tuned  3.86e-03   0.15\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "name_lasso_tuned = 'lasso_tuned'\n",
    "lasso_tuned = Lasso()\n",
    "\n",
    "# Define parameter grid to tune\n",
    "lasso_params = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'normalize': [True, False],\n",
    "               'fit_intercept': [True, False],\n",
    "               'max_iter': [100, 1000, 10000],\n",
    "               'tol': [0.001, 0.01, 0.1]}\n",
    "\n",
    "# Initialize GridSearch tuner\n",
    "grid_search = GridSearchCV(estimator=lasso_tuned, param_grid=lasso_params, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fitting\n",
    "grid_search.fit(X, y)\n",
    "print(f'Best LASSO parameters: {grid_search.best_params_}')\n",
    "\n",
    "# Predicting\n",
    "best_lasso = grid_search.best_estimator_\n",
    "preds_lasso_tuned = best_lasso.predict(X)\n",
    "\n",
    "# Metrics - MAE\n",
    "mae_lasso_tuned = mean_absolute_error(y, preds_lasso_tuned)\n",
    "\n",
    "# Metrics - CV\n",
    "cv_results_lasso_tuned = cross_val_score(best_lasso, X, y, cv=8, scoring='neg_mean_absolute_error')\n",
    "cv_lasso_tuned = abs(cv_results_lasso_tuned).mean()\n",
    "\n",
    "# Format metrics\n",
    "metrics_lasso_tuned = np.array([name_lasso_tuned,'{:0.2e}'.format(mae_lasso_tuned), '{:.2f}'.format(cv_lasso_tuned)]).reshape((1, 3))\n",
    "\n",
    "# Combine metrics in single df\n",
    "if name_lasso_tuned not in metrics.index:\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(metrics_lasso_tuned, columns=['model', 'MAE', 'CV_MAE']).set_index('model')],\n",
    "                        axis=0)\n",
    "\n",
    "# Show results\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c9bf4",
   "metadata": {},
   "source": [
    "## 6.2 Tuned standardised LASSO regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65265cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LASSO parameters with standardiser: {'lasso__alpha': 0.1, 'lasso__fit_intercept': True, 'lasso__max_iter': 100, 'lasso__normalize': False, 'lasso__tol': 0.01}\n",
      "                      MAE CV_MAE\n",
      "model                           \n",
      "lr               9.58e-16   0.78\n",
      "lr_std           2.43e-16   0.32\n",
      "lr_pca           2.94e-02   0.31\n",
      "lr_pca_all       2.86e-02   0.72\n",
      "lasso            2.58e-02   0.16\n",
      "lasso_std        1.68e-01   0.19\n",
      "lasso_tuned      3.86e-03   0.15\n",
      "lasso_std_tuned  8.58e-02   0.16\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "name_lasso_std_tuned = 'lasso_std_tuned'\n",
    "ss_lasso_tuned = StandardScaler()\n",
    "lasso_std_tuned = Lasso()\n",
    "pipeline_lasso_std_tuned = Pipeline([('scaler', ss_lasso_tuned), ('lasso', lasso_std_tuned)])\n",
    "\n",
    "# Define parameter grid to tune\n",
    "lasso_std_params = {'lasso__alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                    'lasso__normalize': [True, False],\n",
    "                    'lasso__fit_intercept': [True, False],\n",
    "                    'lasso__max_iter': [100, 1000, 10000],\n",
    "                    'lasso__tol': [0.001, 0.01, 0.1]}\n",
    "\n",
    "# Initialize GridSearch tuner\n",
    "grid_search_std = GridSearchCV(estimator=pipeline_lasso_std_tuned, param_grid=lasso_std_params, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fitting\n",
    "grid_search_std.fit(X, y)\n",
    "print(f'Best LASSO parameters with standardiser: {grid_search_std.best_params_}')\n",
    "\n",
    "# Predicting\n",
    "best_lasso_std = grid_search_std.best_estimator_\n",
    "preds_lasso_std_tuned = best_lasso_std.predict(X)\n",
    "\n",
    "# Metrics - MAE\n",
    "mae_lasso_std_tuned = mean_absolute_error(y, preds_lasso_std_tuned)\n",
    "\n",
    "# Metrics - CV\n",
    "cv_results_lasso_std_tuned = cross_val_score(best_lasso_std, X, y, cv=8, scoring='neg_mean_absolute_error')\n",
    "cv_lasso_std_tuned = abs(cv_results_lasso_std_tuned).mean()\n",
    "\n",
    "# Format metrics\n",
    "metrics_lasso_std_tuned = np.array([name_lasso_std_tuned,'{:0.2e}'.format(mae_lasso_std_tuned), '{:.2f}'.format(cv_lasso_std_tuned)]).reshape((1, 3))\n",
    "\n",
    "# Combine metrics in single df\n",
    "if name_lasso_std_tuned not in metrics.index:\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(metrics_lasso_std_tuned, columns=['model', 'MAE', 'CV_MAE']).set_index('model')],\n",
    "                        axis=0)\n",
    "\n",
    "# Show results\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693f19d",
   "metadata": {},
   "source": [
    "## 6.3 Tuned LASSO feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e16a837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lr       lr_std       lasso lasso_std lasso_tuned lasso_std_tuned\n",
      "0   Feature185     Feature5   Feature66       NaN   Feature16      Feature974\n",
      "1    Feature66   Feature875   Feature80       NaN   Feature17      Feature983\n",
      "2    Feature88   Feature815  Feature667       NaN   Feature14     Feature1047\n",
      "3    Feature77   Feature755  Feature187       NaN   Feature23             NaN\n",
      "4    Feature64   Feature429         NaN       NaN   Feature19             NaN\n",
      "5    Feature86   Feature845         NaN       NaN  Feature399             NaN\n",
      "6   Feature116   Feature278         NaN       NaN  Feature301             NaN\n",
      "7   Feature692  Feature1287         NaN       NaN   Feature40             NaN\n",
      "8   Feature691   Feature785         NaN       NaN  Feature400             NaN\n",
      "9    Feature80     Feature4         NaN       NaN  Feature398             NaN\n",
      "10  Feature667   Feature414         NaN       NaN  Feature815             NaN\n",
      "11  Feature689   Feature399         NaN       NaN   Feature21             NaN\n",
      "12  Feature755  Feature1105         NaN       NaN  Feature414             NaN\n",
      "13  Feature597  Feature1285         NaN       NaN    Feature9             NaN\n",
      "14  Feature845  Feature1143         NaN       NaN   Feature15             NaN\n",
      "15  Feature595  Feature1061         NaN       NaN    Feature1             NaN\n",
      "16  Feature754   Feature998         NaN       NaN  Feature755             NaN\n",
      "17  Feature255  Feature1094         NaN       NaN   Feature38             NaN\n",
      "18  Feature750   Feature369         NaN       NaN  Feature300             NaN\n",
      "19  Feature844   Feature377         NaN       NaN  Feature756             NaN\n"
     ]
    }
   ],
   "source": [
    "# Initialize LASSO model names and link to regressor\n",
    "lasso_tuned_names = {'lasso_tuned': best_lasso,\n",
    "                     'lasso_std_tuned': best_lasso_std}\n",
    "\n",
    "# Append LASSO most important features to DataFrame created previously for linear regression models\n",
    "for lasso_name in lasso_tuned_names:\n",
    "    \n",
    "    # Create temporary DataFrame with all feature importances for model,\n",
    "    # Handle AttributeError if estimator is a pipeline:\n",
    "    try:\n",
    "        feature_df = pd.DataFrame({'Feature': X.columns,\n",
    "                                   'Coefficient': lasso_tuned_names[lasso_name].coef_,\n",
    "                                   'Importance': abs(lasso_tuned_names[lasso_name].coef_)})\n",
    "    except AttributeError:\n",
    "        feature_df = pd.DataFrame({'Feature': X.columns,\n",
    "                                   'Coefficient': lasso_tuned_names[lasso_name].named_steps['lasso'].coef_,\n",
    "                                   'Importance': abs(lasso_tuned_names[lasso_name].named_steps['lasso'].coef_)})\n",
    "    else:\n",
    "        feature_df = pd.DataFrame({'Feature': X.columns,\n",
    "                                   'Coefficient': lasso_tuned_names[lasso_name].coef_,\n",
    "                                   'Importance': abs(lasso_tuned_names[lasso_name].coef_)})\n",
    "\n",
    "    # Avoid adding duplicate columns\n",
    "    if lasso_name not in important_features.columns:\n",
    "        # Add the most important non-null features of the LASSO model to the important_features df\n",
    "        important_features = pd.concat([important_features,\n",
    "                                        feature_df[feature_df.Importance > 0]\n",
    "                                            .sort_values(by='Importance', ascending=False)\n",
    "                                            .reset_index()\n",
    "                                            .Feature\n",
    "                                            .rename(lasso_name)\n",
    "                                            .head(20)],\n",
    "                                       axis=1)\n",
    "\n",
    "# See all important features for all models\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0d4a4",
   "metadata": {},
   "source": [
    "# 7. Conclusion\n",
    "\n",
    "## 7.1 Models fitted\n",
    "\n",
    "In conclusion, 8 different models were fitted\n",
    "\n",
    "* Linear regression, with and without standardisation and with and without PCA\n",
    "* LASSO regression, with and wthout standardisation and with and without hyperparameter tuning.\n",
    "\n",
    "## 7.2 Model metrics\n",
    "\n",
    "For each model, Several metrics were computed for comparison:\n",
    "\n",
    "* The metric of choice was the mean absolute error (MAE).\n",
    "* Each model was subsequently fitted using 8-fold cross-validation to assess the impact of leaving out each sample of the dataset individually, using the average MAE as a metric (CV_MAE).\n",
    "\n",
    "While the first (MEA) can be assimilated to a standard training error, the second (CV_MAE) can be assimilated to a standard testing error (even though in this case it is really a cross-validation score given the small sample size available, see full discussion in the modelling strategy).\n",
    "\n",
    "Since the difference between the training and testing error is assimilated to overfitting (when training error becomes significantly smaller than the testing error), the absolute difference between MAE and CV_MAE is calculated as a metric of model overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b31f59ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'ScoreDiff' not in metrics.columns:\n",
    "    metrics['ScoreDiff'] = np.round(abs(metrics['MAE'].astype('float') - metrics['CV_MAE'].astype('float')), 2)\n",
    "\n",
    "metrics.reset_index(inplace=True)\n",
    "metrics['MAE'] = metrics.MAE.astype('float')\n",
    "metrics['CV_MAE'] = metrics.CV_MAE.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f50187fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "sns.barplot(data=metrics,\n",
    "            x='model',\n",
    "            y='ScoreDiff', \n",
    "            order=metrics.sort_values(by=['ScoreDiff'], ascending=True).set_index('model').index,\n",
    "            palette=colours,\n",
    "            ax=axes[0])\n",
    "\n",
    "sns.barplot(data=metrics,\n",
    "            x='model',\n",
    "            y='MAE', \n",
    "            order=metrics.sort_values(by=['MAE'], ascending=False).set_index('model').index,\n",
    "            palette=[colours[i] for i in [0, 1, 4, 6, 2, 3, 7, 5]],\n",
    "            ax=axes[1])\n",
    "\n",
    "sns.barplot(data=metrics,\n",
    "            x='model',\n",
    "            y='CV_MAE', \n",
    "            order=metrics.sort_values(by=['CV_MAE'], ascending=True).set_index('model').index,\n",
    "            palette=[colours[i] for i in [3, 2, 1, 0, 4, 5, 6, 7]],\n",
    "            ax=axes[2])\n",
    "\n",
    "axes[0].tick_params(labelrotation=90)\n",
    "axes[1].tick_params(labelrotation=90)\n",
    "axes[2].tick_params(labelrotation=90)\n",
    "axes[0].set_title('Difference between MAE and CV score by model')\n",
    "axes[1].set_title('Mean absolute error by model')\n",
    "axes[2].set_title('Cross-validation score by model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12c901e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             model           MAE  CV_MAE  ScoreDiff\n",
      "0               lr  9.580000e-16    0.78       0.78\n",
      "1           lr_std  2.430000e-16    0.32       0.32\n",
      "2           lr_pca  2.940000e-02    0.31       0.28\n",
      "3       lr_pca_all  2.860000e-02    0.72       0.69\n",
      "4            lasso  2.580000e-02    0.16       0.13\n",
      "5        lasso_std  1.680000e-01    0.19       0.02\n",
      "6      lasso_tuned  3.860000e-03    0.15       0.15\n",
      "7  lasso_std_tuned  8.580000e-02    0.16       0.07\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041117aa",
   "metadata": {},
   "source": [
    "## 7.3 Model performance comparison\n",
    "\n",
    "Overall, the models performed best in the following order: tuned LASSO > LASSO > PCA > linear regression.\n",
    "\n",
    "* As stated previously, the best models for fitting all 8 samples exactly are the inear regression modelss which use all possible predictors. Although they technically provide the best answer to the assignment, these models have no meaning and provide no explainability.\n",
    "\n",
    "\n",
    "* When considering the difference between the MAE and CV_MAE as a metric for detecting overfitting, the best performing model is lasso_std, with almost equal MAE and CV_MAE. However, as seen above, this model includes none of the predictors and only fits the targets using the intercept. The fact that the LASSO regressor set all predictors to 0 is probably a symptom of the sample size being too small to be fit efficiently. Furthermore, it is only the 4th best model at predicting unseen targets, and it is by far the worst model at fitting all 8 targets, which is the baseline assignment. For these reasons, let's look further to find the \"best simplest model\" we are looking for.\n",
    "\n",
    "\n",
    "* The model that performs best at predicting unseen targets (for which CV_MAE is smallest) is the lasso_tuned model. This model performs exceedingly well at fitting the training data as well, with an even lower MAE, an indication that the model is still overfit to the training dataset, although, as stated above, this is almost impossible to achieve given the very small sample size and the large variance in the samples.\n",
    "\n",
    "\n",
    "* Other contenders for the \"best simplest model\" are the regular LASSO model (lasso) and the tuned and standardised LASSO model (lasso_std_tuned), which are second and third best at minimising the difference between MAE and CV_MAE, are good at fitting the provided targets and are almost as good as the lasso_std model at predicting unseen targets. The biggest difference is that they perform worse at fitting the 8 targets (higher MAE) than lasso_tuned. This may be an indication that lasso_tuned overfits the targets more than the other models.\n",
    "\n",
    "## 7.4 \"Best simplest model\"\n",
    "\n",
    "The \"best simplest model\" fit in this exercise is among the lasso_tuned, lasso and lasso_std_tuned models. The \"best simplest model\" will be determined based on 3 arguments: metrics, simplicity and explainability.\n",
    "\n",
    "### The metrics argument\n",
    "\n",
    "\n",
    "From the metrics point of view, all three models perform equally well on predicting unseen samples as indicated by their low cross- validation scores (low CV_MAE). The lasso_tuned model obtains the best fit to the 8 targets, followed by the lasso and the lasso_std_tuned model, which is the worst. However, this is an indication that the lasso_tuned model is the least overfit, leading to a lower MAE - CV_MAE difference. \n",
    "\n",
    "Overall, the **lasso_tuned** model performs best metrics-wise, followed by the lasso model, and then the lasso_std_tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6a0a90b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             model      MAE  CV_MAE  ScoreDiff\n",
      "4            lasso  0.02580    0.16       0.13\n",
      "6      lasso_tuned  0.00386    0.15       0.15\n",
      "7  lasso_std_tuned  0.08580    0.16       0.07\n"
     ]
    }
   ],
   "source": [
    "print(metrics[metrics.model.isin(['lasso_tuned', 'lasso', 'lasso_std_tuned'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0041d",
   "metadata": {},
   "source": [
    "### The simplicity argument\n",
    "\n",
    "From the simplicity point of view, the lasso_std_tuned model is the simplest of the models, using only 3 predictors for similar goodness of fit and cross-validation scores. The lasso model includes only 4 predictors and is the second simplest. The lasso_tuned model contains 422 features and is by far the most complex model. A case can also be made for the lasso model that is simpler from the modelling perspective, if computing time becomes an issue with larger datasets. \n",
    "\n",
    "Overall, the **lasso_std_tuned** is the simplest model, followed by lasso and lasso_tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "160218a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuned LASSO model includes 422 non-zero coefficients\n",
      "The base LASSO model includes 4 non-zero coefficients\n",
      "The tuned and standardised LASSO model includes 3 non-zero coefficients\n"
     ]
    }
   ],
   "source": [
    "print(f'The tuned LASSO model includes {best_lasso.coef_[best_lasso.coef_ != 0].shape[0]} non-zero coefficients')\n",
    "print(f'The base LASSO model includes {lasso.coef_[lasso.coef_ != 0].shape[0]} non-zero coefficients')\n",
    "print('The tuned and standardised LASSO model includes',\n",
    "      best_lasso_std.named_steps['lasso'].coef_[best_lasso_std.named_steps['lasso'].coef_ > 0].shape[0],\n",
    "      'non-zero coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa3cb6",
   "metadata": {},
   "source": [
    "### The explainability argument\n",
    "\n",
    "Explainability is an important metric of a linear model since such models allow to determine easily which predictors contribute most to its fit. The top 5 features of both models are detailed to assess their link with the target.\n",
    "\n",
    "The 5 top features of the lasso_tuned model are:\n",
    "\\[List anonymised\\]\n",
    "\n",
    "\\[Explanation anonymised\\]\n",
    "\n",
    "The 3 features of the lasso_std_tuned model are:\n",
    "\\[List anonymised\\]\n",
    "\n",
    "\\[Explanation anonymised\\]\n",
    "\n",
    "The 4 features of the lasso model are:\n",
    "\\[List anonymised\\]\n",
    "\n",
    "\\[Explanation anonymised\\]\n",
    "\n",
    "\\[Explanation anonymised\\] The **lasso_tuned** is by far the most easily interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2092a7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lasso lasso_tuned lasso_std_tuned\n",
      "0   Feature66   Feature16      Feature974\n",
      "1   Feature80   Feature17      Feature983\n",
      "2  Feature667   Feature14     Feature1047\n",
      "3  Feature187   Feature23             NaN\n",
      "4         NaN   Feature19             NaN\n"
     ]
    }
   ],
   "source": [
    "print(important_features[['lasso', 'lasso_tuned', 'lasso_std_tuned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf62ca4",
   "metadata": {},
   "source": [
    "### Overall, \n",
    "\n",
    "* The **lasso_tuned** model provides a very good fit to the target data and performs the best at predicting unseen targets.\n",
    "* The **lasso_std_tuned** model is simpler since it based on only 3 features, which is an indication of its lack of overfitting\n",
    "* The **lasso_tuned** model is easier to interpret since it is based on \\[explanation anonymised\\]\n",
    "\n",
    "The “best simplest model” fit in this exercise is lasso_tuned, a LASSO regressor with tuned hyperparameters using a GridSearchCV resulting in: alpha=0.001, fit_intercept=False, max_iter=100, normalize=True, tol=0.1. The mean absolute error of this model to fit the 8 targets is about 0.004. The cross-validation mean absolute error obtained by this model, a metric of how well the model should be able to fit unseen samples (and therefore to have captured the true variance of the data) is 0.15. This model is likely overfit to the data given its 422 features and very low fit mean absolute error, but fits the targets very well and performs the best when predicting the target of samples left out of the dataset. Furthermore, its features are easily interpretable which makes it more explanable than the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7bb8aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.001, fit_intercept=False, max_iter=100, normalize=True, tol=0.1)\n"
     ]
    }
   ],
   "source": [
    "print(best_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfdcd9",
   "metadata": {},
   "source": [
    "If the purpose of the model would have been to predict the targets of new samples, the lasso_std_tuned would likely produce equally good (or bad) results for seen and unseen samples, with a cross-validation MAE of 0.16, but would perform poorly on the provided targets, with an MAE of about 0.085, and is less interpretable than lasso_tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1cafb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.1, max_iter=100, normalize=False, tol=0.01)\n"
     ]
    }
   ],
   "source": [
    "print(best_lasso_std.named_steps['lasso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0798f",
   "metadata": {},
   "source": [
    "# Other options to consider\n",
    "\n",
    "Further feature selection methods could be explored, such as \n",
    "* Attempting simple linear regression based on the top LASSO features\n",
    "* Decision tree based on the top LASSO features (to avoid overfitting)\n",
    "* Forward and Backward feature selection using SequentialFeatureSelector\n",
    "* SelectFromModel combined with LinearSVC\n",
    "* Univariate feature selection based on statistical correlation (e.g. SelectKBest)\n",
    "* Explore the impact of the order of samples in the DataFrame on LASSO regression results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
